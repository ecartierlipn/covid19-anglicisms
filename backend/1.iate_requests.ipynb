{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to query IATE database with the REST API and save it to database\n",
    "see : https://iate.europa.eu/developers\n",
    "\n",
    "and : https://documenter.getpostman.com/view/4028985/RztoMTwn?version=latest#api-keys\n",
    "\n",
    "\n",
    "see also (EU responses to covid-19) : https://eur-lex.europa.eu/homepage.html?locale=en\n",
    "\n",
    "and : https://op.europa.eu/en/web/eudatathon/covid-19\n",
    "\n",
    "and : https://eur-lex.europa.eu/homepage.html\n",
    "\n",
    "http://inmyownterms.com/covid-19-glossaries-dictionaries-terminology/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Database / tables creation (sqlite3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# create database and tables\n",
    "# https://www.sqlitetutorial.net/\n",
    "\n",
    "import sqlite3\n",
    "    \n",
    "conn = sqlite3.connect('db/iate-covid19.db')\n",
    "\n",
    "c = conn.cursor()\n",
    "# Create tables\n",
    "langs = ['cs','da','de','en','es','fi','fr','it','nl','is','no','pt']\n",
    "\n",
    "\n",
    "c.execute('''DROP TABLE IF EXISTS concepts''')\n",
    "c.execute('''CREATE TABLE concepts\n",
    "             (id INT PRIMARY KEY, en_lexemes TEXT, cs_def TEXT,da_def TEXT,de_def TEXT,en_def TEXT,es_def TEXT,fi_def TEXT,fr_def TEXT,it_def TEXT,nl_def TEXT,is_def TEXT,no_def TEXT,pt_def TEXT)''')\n",
    "# Create table concepts_crossrefs\n",
    "c.execute('''DROP TABLE IF EXISTS concepts_relations''')\n",
    "c.execute('''CREATE TABLE concepts_relations\n",
    "             (id_concept1 INT, id_concept2 INT, relation INT, UNIQUE(id_concept1,id_concept2, relation))''')\n",
    "# Create table concepts_crossrefs_def\n",
    "c.execute('''DROP TABLE IF EXISTS concepts_relations_types''')\n",
    "c.execute('''CREATE TABLE concepts_relations_types\n",
    "             (id INT PRIMARY KEY, label VARCHAR(50)''')\n",
    "# Create table concepts_domains\n",
    "c.execute('''DROP TABLE IF EXISTS concepts_domains''')\n",
    "c.execute('''CREATE TABLE concepts_domains\n",
    "             (id_concept INT, id_domain INT, UNIQUE(id_concept,id_domain))''')\n",
    "# Create table domains\n",
    "c.execute('''DROP TABLE IF EXISTS domains''')\n",
    "c.execute('''CREATE TABLE domains\n",
    "             (id TEXT PRIMARY KEY, label TEXT, level INT, parent TEXT, label_var TEXT)''')\n",
    "# Create table langages\n",
    "c.execute('''DROP TABLE IF EXISTS languages''')\n",
    "c.execute('''CREATE TABLE languages\n",
    "             (id VARCHAR(10) PRIMARY KEY, label TEXT)''')\n",
    "# Create table lexemes\n",
    "c.execute('''DROP TABLE IF EXISTS lexemes''')\n",
    "c.execute('''CREATE TABLE lexemes\n",
    "             (id INT PRIMARY KEY, value VARCHAR(255), query VARCHAR(255), id_concept INT, lang VARCHAR(10), type INT, context TEXT)''')\n",
    "# Create table lexemes_types\n",
    "c.execute('''DROP TABLE IF EXISTS lexemes_types''')\n",
    "c.execute('''CREATE TABLE lexemes_types\n",
    "             (id INT PRIMARY KEY, label VARCHAR(50))''')\n",
    "# select examples\n",
    "c.execute(\"SELECT * FROM concepts\")\n",
    "print(c.fetchone())\n",
    "print(c.fetchall())\n",
    "for row in c.execute('SELECT * FROM lexemes'):\n",
    "    print(row)\n",
    "\n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get available languages and populate database / table languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get languages\n",
    "import requests\n",
    "\n",
    "url = \"https://iate.europa.eu/em-api/inventories/_languages?trans_lang=en&expand=true&limit=300&offset=0\"\n",
    "langs = ['cs','da','de','en','es','fi','fr','it','nl','is','no','pt']\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'Accept': 'application/json'\n",
    "}\n",
    "\n",
    "resp = requests.request(\"GET\", url, headers=headers, data = payload)\n",
    "\n",
    "if resp.status_code == 200:\n",
    "    #contents = print(response.text.encode('utf8'))\n",
    "    res = []\n",
    "    for item in resp.json()['items']:\n",
    "        res.append((item['code'],item['name']))\n",
    "        #print(item['code'], item['name'])\n",
    "\n",
    "conn = sqlite3.connect('db/iate-covid19.db')\n",
    "c = conn.cursor()\n",
    "c.executemany('INSERT INTO languages VALUES (?,?)', res)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get term types and save them to database / table lexemes_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 abbrev\n",
      "1 formula\n",
      "2 phrase\n",
      "3 short form\n",
      "4 term\n",
      "5 lookup form\n",
      "6 appellation\n",
      "{0: 'abbrev', 1: 'formula', 2: 'phrase', 3: 'short form', 4: 'term', 5: 'lookup form', 6: 'appellation'}\n"
     ]
    }
   ],
   "source": [
    "# term types\n",
    "import requests\n",
    "\n",
    "url = \"https://iate.europa.eu/em-api/inventories/_term-types?trans_lang=en&expand=true&limit=20&offset=0\"\n",
    "payload = {}\n",
    "headers = {\n",
    "    'Accept': 'application/json'\n",
    "}\n",
    "\n",
    "resp = requests.request(\"GET\", url, headers=headers, data = payload)\n",
    "\n",
    "if resp.status_code == 200:\n",
    "    res=[]\n",
    "    for item in resp.json()['items']:\n",
    "        print(item['code'], item['name'])\n",
    "        res.append((item['code'],item['name']))\n",
    "\n",
    "conn = sqlite3.connect('db/iate-covid19.db')\n",
    "c = conn.cursor()\n",
    "c.executemany('INSERT INTO lexemes_types VALUES (?,?)', res)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "def get_id_labels(table, db):\n",
    "    conn = sqlite3.connect(db)\n",
    "    c = conn.cursor()\n",
    "    res ={}\n",
    "    query = 'SELECT id,label FROM ' + table\n",
    "    #print(query)\n",
    "    for row in c.execute(query):\n",
    "        res[row[0]]=row[1]\n",
    "        \n",
    "    conn.close()\n",
    "    return res\n",
    "\n",
    "\n",
    "termtypes = get_id_labels('lexemes_types','db/iate-covid19.db')\n",
    "print(termtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get domains and populate database / table domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill domains\n",
    "# get domains\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "def parse_tree_domains(domain, parent, parentname, res):\n",
    "        if 'lookups' in domain.keys():\n",
    "            lookup = \",\".join(domain['lookups'])\n",
    "        else:\n",
    "            lookup = ''\n",
    "        if parentname =='' or parentname =='Domain code not specified':\n",
    "            parentname = domain['name']\n",
    "        else:\n",
    "            parentname = parentname +' > ' + domain['name'] \n",
    "        #print(parentname)\n",
    "        res.append((domain['code'],parentname,domain['level'],parent,lookup))\n",
    "        if 'subdomains' in domain.keys():\n",
    "            for d in domain['subdomains']:\n",
    "                parse_tree_domains(d,domain['code'],parentname, res)\n",
    "        \n",
    "def query_domains():\n",
    "    url = \"https://iate.europa.eu/em-api/domains/_tree\"\n",
    "    payload = {}\n",
    "    headers = {\n",
    "      'Accept': 'application/json'\n",
    "    }\n",
    "    resp = requests.request(\"GET\", url, headers=headers, data = payload)\n",
    "    if resp.status_code == 200:\n",
    "        res = []\n",
    "        data = resp.json()['items']\n",
    "        #print(data)\n",
    "        for d in data:\n",
    "            parse_tree_domains(d, '','', res)\n",
    "        return res\n",
    "                    \n",
    "conn = sqlite3.connect('db/iate-covid19.db')\n",
    "c = conn.cursor()\n",
    "res = query_domains()\n",
    "#print(res)\n",
    "c.executemany('INSERT INTO domains VALUES (?,?,?,?,?)', res)\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('5C182C28AE7A4E578AC83588DDCC4235', 'POLITICS > political framework > political philosophy > democracy > deliberative democracy', 5, '8CA089860329450C9C521843B6F7032B', 'discursive democracy,democratic deliberation')\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('db/iate-covid19.db')\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT * FROM domains where level=5\")\n",
    "print(c.fetchone())\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "def get_label(id, table, db):\n",
    "    conn = sqlite3.connect(db)\n",
    "    c = conn.cursor()\n",
    "    query = 'SELECT label FROM ' + table + ' where id=\"' + id + '\"'\n",
    "    #print(query)\n",
    "    c.execute(query)\n",
    "    res = c.fetchall()\n",
    "            \n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return res\n",
    "\n",
    "def get_domains(table, db):\n",
    "    conn = sqlite3.connect(db)\n",
    "    c = conn.cursor()\n",
    "    res ={}\n",
    "    query = 'SELECT id,label FROM ' + table\n",
    "    #print(query)\n",
    "    for row in c.execute(query):\n",
    "        res[row[0]]=row[1]\n",
    "        \n",
    "    conn.close()\n",
    "    return res\n",
    "\n",
    "\n",
    "get_label('9A4F05026F3245BD95BE7DFCE54764AC', 'domains','db/iate-covid19.db')\n",
    "domains = get_domains('domains','db/iate-covid19.db')\n",
    "#for d in domains.keys():\n",
    "#    print(d,domains[d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate concepts and lexemes tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 entries\n",
      "concept fields : 14\n",
      "concept relations : 5\n",
      "concept domains : 2\n",
      "69 lexemes\n",
      "14 fields\n",
      "INSERT INTO concepts VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)\n",
      "Error : UNIQUE constraint failed: concepts.id\n",
      "3 fields\n",
      "INSERT INTO concepts_relations VALUES (?,?,?)\n",
      "Error : UNIQUE constraint failed: concepts_relations.id_concept1, concepts_relations.id_concept2, concepts_relations.relation\n",
      "2 fields\n",
      "INSERT INTO concepts_domains VALUES (?,?)\n",
      "Error : UNIQUE constraint failed: concepts_domains.id_concept, concepts_domains.id_domain\n",
      "7 fields\n",
      "INSERT INTO lexemes VALUES (?,?,?,?,?,?,?)\n",
      "Error : UNIQUE constraint failed: lexemes.id\n"
     ]
    }
   ],
   "source": [
    "import pprint,pickle, re\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "def query_code_lexemes(query,lang='en'):\n",
    "    '''\n",
    "    Query IATE db for a concept code and return the lexical items in the requested language.\n",
    "    \n",
    "        Parameters:\n",
    "                    query (str): the concept code in IATE\n",
    "                    lang (str): the language code\n",
    "\n",
    "        Returns:\n",
    "                    res (list): the list of lexemes\n",
    "    \n",
    "    '''\n",
    "    resp = requests.post('https://iate.europa.eu/em-api/entries/_search?expand=true&limit=5', \n",
    "                     json={'query':query,'search_in_fields':[8], 'source':'en'})\n",
    "    if resp.status_code == 200:\n",
    "        res=[]\n",
    "        #print(len(resp.json()['items']), \" entries\")\n",
    "        # just get first one\n",
    "        if 'items' in resp.json():\n",
    "            item = resp.json()['items'][0]\n",
    "            # get lang entries     \n",
    "            if 'language' in item.keys() and lang in item['language']:\n",
    "                for entry in item['language'][lang]['term_entries']:\n",
    "                    res.append(entry['term_value'])\n",
    "            return res\n",
    "        else:\n",
    "            print(\"Strange behavior : no lexemes for this code :\", resp.json())\n",
    "            return []\n",
    "        \n",
    "    else:\n",
    "        print(resp.status_code)\n",
    "        return False\n",
    "     \n",
    "def query_code_id(query):\n",
    "    '''\n",
    "    Query IATE db for a concept code and return the id of the concept.\n",
    "    \n",
    "        Parameters:\n",
    "                    query (int): the concept code in IATE\n",
    "\n",
    "        Returns:\n",
    "                    id (int): the id of the concept\n",
    "    \n",
    "    '''\n",
    "    resp = requests.post('https://iate.europa.eu/em-api/entries/_search?expand=true&limit=5', \n",
    "                     json={'query':query,'search_in_fields':[8], 'source':'en'})\n",
    "    if resp.status_code == 200:\n",
    "        res=[]\n",
    "        #print(len(resp.json()['items']), \" entries\")\n",
    "        # just get first one\n",
    "        if 'items' in resp.json():\n",
    "            item = resp.json()['items'][0]\n",
    "            return item['id']\n",
    "        else :\n",
    "            print(\"Strange behavior : no items for this code\")\n",
    "            print(resp.json())\n",
    "            return ''\n",
    "    else:\n",
    "        print(resp.status_code)\n",
    "        return False\n",
    "  \n",
    "\n",
    "def query_id(query, langs):\n",
    "    '''\n",
    "    Query IATE db for a concept code and return all the linked information (concept, concept relations, concept domains, lexemes).\n",
    "    \n",
    "        Parameters:\n",
    "                    query (int): the concept code in IATE\n",
    "                    langs (list): the list of languages to be queried for lexemes\n",
    "\n",
    "        Returns:\n",
    "                    allitems, concept,concept_rels,concept_domains, lexemes\n",
    "                    allitems (list): the list of all information retrieved\n",
    "                    concept (list): the list of information for the concept (id, list of entries in English, definitions in all required languages, if exist)\n",
    "                    concept_rels (list): the list of the concept relations to other concepts (id_concept1, id_concept2, relation_type)\n",
    "                    concept_domains (list): the list of the domains the concept belongs to (id_concept, id_domain)\n",
    "                    lexemes (list): the list of lexemes linked to the concept, for all required languages (id_lexeme,lexeme_value,id_concept, lang, lexeme_type,context)   \n",
    "    '''\n",
    "\n",
    "    resp = requests.post('https://iate.europa.eu/em-api/entries/_search?expand=true&limit=30', \n",
    "                     json={'query':query,'search_in_fields':[9], 'source':'en', 'targets':langs})\n",
    "    if resp.status_code == 200:\n",
    "        #print(resp.json())\n",
    "        if not('items' in resp.json()):\n",
    "            print(resp.json())\n",
    "            return [], [],[],[], []\n",
    "        print(str(len(resp.json()['items'])) + \" entries\")\n",
    "        items = resp.json()['items']\n",
    "        # structure for displaying results (debug)\n",
    "        allitems=[]\n",
    "        for item in resp.json()['items']:\n",
    "            itemdata={}\n",
    "            # get concept id\n",
    "            itemdata['id'] = query # or item['id']\n",
    "            #print(item['id'],item['score']) # item.keys(), \n",
    "            # crossrefs\n",
    "            if 'crossrefs' in item.keys():\n",
    "                #print(item['crossrefs'])\n",
    "                crossrefs = [(query_code_lexemes(crossref['code']),crossref['type']) for crossref in item['crossrefs']]\n",
    "                concept_rels = [(itemdata['id'], query_code_id(crossref['code']),crossref['type']) for crossref in item['crossrefs']]\n",
    "                itemdata['crossrefs'] = crossrefs\n",
    "                #print(\"Related concepts : \",crossrefs)\n",
    "            else:\n",
    "                concept_rels=[]\n",
    "            # get domains\n",
    "            if 'domains' in item.keys():\n",
    "                domaincodes = [domains[dom['code']]  if dom['code'] in domains else dom['code'] for dom in item['domains']]\n",
    "                concept_domains = [(itemdata['id'],dom['code']) for dom in item['domains']]\n",
    "                itemdata['domains'] = domaincodes\n",
    "                #print('domains:', domaincodes)\n",
    "            else:\n",
    "                concept_domains=[]\n",
    "            # get language entries\n",
    "            if 'language' in item.keys():\n",
    "                # structure for saving to db/table\n",
    "                lexemes=[]\n",
    "                #print(item['language'].keys())\n",
    "                for lang in item['language']:\n",
    "                    if lang in langs:\n",
    "                        # structure for display/debug purposes\n",
    "                        itemdata[lang] = {}\n",
    "                        itemdata[lang]['entries']=[]\n",
    "                        #print('***'*20,\"\\nlang:\",lang,\"\\n\")#,item['language'][lang].keys()\n",
    "                        # definition : we store it at the concept level\n",
    "                        if 'definition' in item['language'][lang].keys():\n",
    "                            #itemdata[lang]['definition']=(item['language'][lang]['definition'],item['language'][lang]['definition_references'][0]['text'])\n",
    "                            itemdata[lang + '_def']= item['language'][lang]['definition'] + \" - \" + item['language'][lang]['definition_references'][0]['text']\n",
    "                        else:\n",
    "                            #itemdata[lang]['definition']=('','') \n",
    "                            itemdata[lang + '_def']=''\n",
    "                        # entries\n",
    "                        for entry in item['language'][lang]['term_entries']:\n",
    "                                #lexemes [(id INT PRIMARY KEY, value TEXT, id_concept INT, lang TEXT, type INT, definition TEXT, context TEXT)]\n",
    "                                itementry = {}\n",
    "                                itementry['value']= entry['term_value']\n",
    "                                # patch for mapping Czech iso code\n",
    "                                if lang == 'cs':\n",
    "                                    lang2 = 'cz'\n",
    "                                    stopw = get_stop_words(lang2)\n",
    "                                else:\n",
    "                                    stopw = get_stop_words(lang)\n",
    "                                itementry['query'] = \" \".join([w for w in re.split(r\"\\W\",entry['term_value'], re.I) if not(w in stopw)])\n",
    "\n",
    "                                itementry['type']= termtypes[entry['type']]\n",
    "                                if 'contexts' in entry.keys(): # just keep first context\n",
    "                                    itementry['context'] = entry['contexts'][0]['context']\n",
    "                                    itementry['context_ref'] = entry['contexts'][0]['reference']['text']\n",
    "                                    if 'language_usage' in entry['contexts'][0].keys():\n",
    "                                        itementry['language_usage'] = entry['contexts'][0]['language_usage']\n",
    "                                    else:\n",
    "                                        itementry['language_usage']=''\n",
    "                                    if 'regional_usage' in entry['contexts'][0].keys():\n",
    "                                        itementry['regional_usage'] = entry['contexts'][0]['regional_usage']\n",
    "                                    else:\n",
    "                                        itementry['regional_usage']=''\n",
    "                                else:\n",
    "                                    itementry['context'] = ''\n",
    "                                    itementry['context_ref'] = ''\n",
    "                                    itementry['language_usage']=''\n",
    "                                    itementry['regional_usage']=''\n",
    "                                    \n",
    "                                lexeme = (entry['id'],itementry['value'],itementry['query'],itemdata['id'], lang, entry['type'],itementry['context'])\n",
    "                                lexemes.append(lexeme)\n",
    "                                itemdata[lang]['entries'].append(itementry)\n",
    "                        allitems.append(itemdata)\n",
    "                        # concept with english_samples and definition\n",
    "                        if 'en' in itemdata.keys():\n",
    "                            #print(itemdata['en'])\n",
    "                            entries = \", \".join([itementry['value'] for itementry in itemdata['en']['entries']])\n",
    "                            lang_defs = [itemdata[lang + '_def'] if lang + '_def' in itemdata else '' for lang in langs]\n",
    "                            concept = [itemdata['id'],entries]\n",
    "                            concept.extend(lang_defs)\n",
    "        # before returning check if concept defined. otherwise, create empty one with default value (no lexemes)\n",
    "        if not('concept' in vars()):\n",
    "            concept = [query,'']\n",
    "        return allitems, concept,concept_rels,concept_domains, lexemes\n",
    "    else:\n",
    "        print(resp.status_code)\n",
    "        return [],[],[],[],[]\n",
    "\n",
    "def save_iate_to_db(data, table, conn):\n",
    "    '''\n",
    "    Save data retrieved from IATE to sqlite database/table\n",
    "    \n",
    "        Parameters:\n",
    "            data(list) : a list of tuples to save to db\n",
    "            table (str): the name of the table to save to\n",
    "            conn (obj): the connection to the sqlite3 db file\n",
    "            \n",
    "        Returns:\n",
    "            True|False (bool) : True or False depending on success\n",
    "    '''\n",
    "    # check data is not empty\n",
    "    if len(data)==0:\n",
    "        print('Empty data')\n",
    "        return False\n",
    "    # first get number of fields in data elements\n",
    "    nb = len(data[0])\n",
    "    placeholders = \",\".join(['?' for i in range(nb)])\n",
    "    print(str(nb) + ' fields')\n",
    "    # generate query\n",
    "    #'INSERT INTO concepts VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)'\n",
    "    query = 'INSERT INTO ' + table + ' VALUES (' + placeholders + ')'\n",
    "    print(query)\n",
    "\n",
    "    try:\n",
    "        #conn=sqlite3.connect(db)\n",
    "        c = conn.cursor()\n",
    "        c.executemany(query,data)\n",
    "        conn.commit()\n",
    "        print(\"Total insertions into \" + table + \": \",conn.total_changes)\n",
    "        #conn.close()\n",
    "        return True\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error : \" + str(e))\n",
    "        return False\n",
    "\n",
    "def save_to_pickle(data,pathdir):  \n",
    "    outfile = open(pathdir,'wb')\n",
    "    pickle.dump(data,outfile)\n",
    "    outfile.close()\n",
    "\n",
    "# main : test on given concept id\n",
    "langs = ['cs','da','de','en','es','fi','fr','it','nl','is','no','pt']\n",
    "id_concept = '3588006'\n",
    "save_dir = './save/'\n",
    "res, concept,concept_rels,concept_domains, lexemes = query_id(id_concept, langs)\n",
    "print(\"concept fields : \" + str(len(concept))) # ok\n",
    "print(\"concept relations : \" + str(len(concept_rels))) # ok\n",
    "print(\"concept domains : \" + str(len(concept_domains))) # ok\n",
    "print(str(len(lexemes)) + \" lexemes\")\n",
    "# save to pickle\n",
    "save_to_pickle(concept, save_dir + id_concept + '_concept.pickle')\n",
    "save_to_pickle(concept_rels, save_dir + id_concept + '_concept_relations.pickle')\n",
    "save_to_pickle(concept_domains, save_dir + id_concept + '_concept_domains.pickle')\n",
    "save_to_pickle(lexemes, save_dir + id_concept + '_lexemes.pickle')\n",
    "        \n",
    "# now populate datababase/tables\n",
    "conn=sqlite3.connect('db/iate-covid19.db')\n",
    "save_iate_to_db([concept], 'concepts', conn)\n",
    "save_iate_to_db(concept_rels, 'concepts_relations', conn)\n",
    "save_iate_to_db(concept_domains, 'concepts_domains', conn)\n",
    "save_iate_to_db(lexemes, 'lexemes', conn)\n",
    "conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch process for the list of covid-19 related concepts (as of July 2020 from IATE website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference data\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "\n",
    "df = pd.read_csv('./resources/OP_Covid19_IATE_2872020.csv')\n",
    "df.drop(['IATE entry URL'], inplace=True, axis=1) # ,'IATE entry URL.1'\n",
    "print(df.info())\n",
    "ids = set(df['IATE ID'].unique())\n",
    "print(\"Unique concepts : \", len(ids))\n",
    "# launch search into IATE db and save data to db\n",
    "# required languages\n",
    "langs = ['cs','da','de','en','es','fi','fr','it','nl','is','no','pt']\n",
    "save_dir = './save/'\n",
    "\n",
    "for id in ids :\n",
    "    id_concept = str(id)\n",
    "    print(\"Processing concept id : \" + id_concept)\n",
    "    res, concept,concept_rels,concept_domains, lexemes = query_id(id_concept, langs)\n",
    "    print(\"concept fields : \" + str(len(concept))) # ok\n",
    "    print(\"concept relations : \" + str(len(concept_rels))) # ok\n",
    "    print(\"concept domains : \" + str(len(concept_domains))) # ok\n",
    "    print(str(len(lexemes)) + \" lexemes\")\n",
    "    # save to pickle\n",
    "    save_to_pickle(concept, save_dir + id_concept + '_concept.pickle')\n",
    "    save_to_pickle(concept_rels, save_dir + id_concept + '_concept_relations.pickle')\n",
    "    save_to_pickle(concept_domains, save_dir + id_concept + '_concept_domains.pickle')\n",
    "    save_to_pickle(lexemes, save_dir + id_concept + '_lexemes.pickle')\n",
    "            \n",
    "    # now populate datababase/tables\n",
    "    conn=sqlite3.connect('db/iate-covid19.db')\n",
    "    save_iate_to_db([concept], 'concepts', conn)\n",
    "    save_iate_to_db(concept_rels, 'concepts_relations', conn)\n",
    "    save_iate_to_db(concept_domains, 'concepts_domains', conn)\n",
    "    save_iate_to_db(lexemes, 'lexemes', conn)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now all data is saved into sqlite db. Check db subdirectory to find aditionnal script to manage db (especially to convert to mysql)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests to db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas,re\n",
    "\n",
    "# 1 Request id concept, definition, list of domains, and for all concerned languages the list of lexicalizations\n",
    "\n",
    "conn = sqlite3.connect('db/iate-covid19.db')\n",
    "conn.row_factory = sqlite3.Row\n",
    "c = conn.cursor()\n",
    "\n",
    "# structure query\n",
    "#q = 'select sql from sqlite_master where type = \"table\" and name = \"concepts\";'\n",
    "#c.execute(q)\n",
    "#print(c.fetchone())\n",
    "#q = 'select d.label as domain from concepts_domains as cd left join domains as d on cd.id_domain = d.id  where cd.id_concept=\"3588006\"'\n",
    "#c.execute(q)\n",
    "#res = [dict(row) for row in c.fetchall()]\n",
    "#print(res)\n",
    "#print(\"*\"*10)\n",
    "\n",
    "# all data in array\n",
    "alldata = []\n",
    "# data query\n",
    "q = 'select id,en_lexemes, en_def from concepts'\n",
    "c.execute(q)\n",
    "res = [dict(row) for row in c.fetchall()]\n",
    "#print(res)\n",
    "#print(\"*\"*10)\n",
    "\n",
    "for elt in res:\n",
    "    # create dict structure for this concept with id_concept,en_lex, all languages lexicalizations, domains\n",
    "    eltdata={}\n",
    "    eltdata['id_concept']= elt['id']\n",
    "    eltdata['iate_link']= 'https://iate.europa.eu/entry/result/' + str(elt['id'])\n",
    "    if 'en_def' in elt:\n",
    "        definition = re.sub(r\"<[^>+?]*?>\",\"\", elt['en_def'])\n",
    "        eltdata['en_def']= definition\n",
    "    else :\n",
    "        eltdata['en_def']= ''\n",
    "\n",
    "    eltdata['en']= elt['en_lexemes']\n",
    "    \n",
    "    # lexemes\n",
    "    lexs = {}\n",
    "    q = 'select * from lexemes where id_concept=\"' + str(elt['id'])  + '\"'\n",
    "    c.execute(q)\n",
    "    for row in c.fetchall():\n",
    "        elt2 = dict(row)\n",
    "        lang = elt2['lang']\n",
    "        if lang in lexs:\n",
    "            data = lexs[lang]\n",
    "            data.append(elt2['value'])\n",
    "            lexs[lang] = data\n",
    "        else:\n",
    "            lexs[lang] = [elt2['value']]\n",
    "    for lang in lexs:\n",
    "        eltdata[lang]= \", \".join(lexs[lang])\n",
    "\n",
    "    # domains\n",
    "    q = 'select d.label as domain from concepts_domains as cd left join domains as d on cd.id_domain = d.id  where cd.id_concept=\"' + str(elt['id'])  + '\"'\n",
    "    c.execute(q)\n",
    "    for row in c.fetchall():\n",
    "        dom = dict(row)\n",
    "        #print(dom)\n",
    "        #print(\"*\"*10)\n",
    "        if 'domains' in eltdata:\n",
    "            data = eltdata['domains']\n",
    "            data.append(dom['domain'])\n",
    "            eltdata['domains']=data\n",
    "        else:\n",
    "            eltdata['domains']=[dom['domain']]\n",
    "    domains =  eltdata['domains']\n",
    "    eltdata['domains']=\", \".join(domains)\n",
    "    #print(eltdata)\n",
    "    alldata.append(eltdata)\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "# save to json file\n",
    "import json\n",
    "with open('iate_data.json', 'w') as f:\n",
    "    json.dump(alldata, f)\n",
    "\n",
    "# then convert to excel and csv\n",
    "pandas.read_json(\"iate_data.json\").to_excel(\"iate_data.json.xlsx\", index=False)\n",
    "pandas.read_json(\"iate_data.json\").to_csv(\"iate_data.json.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SARS-CoV-2': ['cs', 'de', 'es', 'fi', 'fr', 'it', 'nl', 'pt'], '2019-nCoV': ['cs', 'da', 'de', 'es', 'fi', 'fr', 'it', 'nl', 'pt'], 'severe acute respiratory syndrome coronavirus 2': ['da', 'nl'], 'CSPP': ['da', 'de', 'es', 'fr', 'it', 'pt'], 'EWRS': ['cs', 'de'], 'CoV': ['cs', 'da', 'de', 'es', 'fi', 'fr', 'it', 'nl'], 'coronavirus': ['da', 'es', 'fr', 'it', 'nl'], 'interferon': ['da', 'it', 'nl'], 'IFN': ['de', 'fr', 'it'], 'LVP': ['fr'], 'LVP solution': ['fr'], 'web conference': ['it'], 'CEAOB': ['cs', 'fi', 'fr', 'it', 'nl'], 'MSC': ['it'], 'GPMB': ['de', 'es', 'fr', 'it', 'nl'], 'Global Preparedness Monitoring Board': ['it'], 'ritonavir': ['cs', 'da', 'es', 'fr', 'it', 'nl', 'pt'], 'contact': ['nl'], 'conference call': ['it'], 'RMS': ['de'], 'triage': ['cs', 'da', 'fi', 'fr', 'it', 'nl'], 'immunoglobulin': ['da'], 'capsid': ['da'], 'EU Integrated Political Crisis Response (IPCR) arrangements': ['da', 'de', 'fi', 'fr', 'fr', 'pt'], 'EU IPCR arrangements': ['da', 'de', 'fi', 'fr', 'fr', 'pt'], 'IPCR': ['da', 'de', 'fi', 'fr', 'pt'], 'CCA': ['da', 'de', 'it', 'nl'], 'EU Integrated Political Crisis Response arrangements': ['fr'], 'ipcr arrangements': ['fr'], 'crisis coordination arrangements': ['fr'], 'interstitium': ['da', 'fr', 'nl'], 'index case': ['nl'], 'POCT': ['cs', 'da', 'it'], 'point-of-care testing': ['da'], 'Middle East Respiratory Syndrome Coronavirus': ['nl'], 'COVID-19': ['cs', 'de', 'es', 'fr', 'nl', 'pt'], 'chloroquine': ['fr', 'nl'], 'SARS': ['cs', 'de', 'fi', 'it', 'nl', 'pt'], 'severe acute respiratory syndrome': ['nl'], 'isolation': ['da'], 'preclinical test': ['nl'], 'pre-clinical test': ['nl'], 'pre-clinical testing': ['nl'], 'severe acute respiratory syndrome-related coronavirus': ['nl'], 'ARDS': ['de', 'de', 'it', 'nl'], 'AAA': ['da', 'de', 'es', 'fr', 'pt'], 'AAA rating': ['da', 'de', 'es', 'fr', 'pt'], 'cluster': ['da', 'it'], 'cluster of cases': ['da', 'it'], 'disease cluster': ['da', 'it'], 'ERP': ['da', 'de', 'it'], 'FDI': ['da'], 'viral spike protein': ['nl'], 'spike protein': ['nl'], 'spike glycoprotein': ['nl'], 'virulence': ['cs', 'fr'], 'MERS': ['cs', 'de', 'fi', 'fr', 'it', 'nl'], 'Middle East respiratory syndrome': ['da', 'nl'], 'GAVI Alliance': ['cs', 'da', 'de', 'fi', 'fr', 'it', 'pt', 'pt'], 'ICSR': ['cs', 'fr', 'it', 'nl'], 'ICSRs': ['cs', 'fr', 'it', 'nl'], 'immunisation': ['fr'], 'cytokine': ['cs', 'da', 'fr', 'nl'], 'sunset clause': ['nl'], 'antiviral drug': ['de', 'de', 'es', 'es', 'fr', 'fr', 'pt', 'pt'], 'antiviral': ['de', 'es', 'fr', 'pt'], 'antivirals': ['de', 'es', 'fr', 'pt'], 'antiviral medicine': ['de', 'es', 'fr', 'pt'], 'antiviral medication': ['de', 'es', 'fr', 'pt'], 'UCPM': ['de', 'it'], 'HSC': ['cs', 'da', 'de', 'nl'], 'social distancing': ['nl'], 'containment': ['nl'], 'CRII': ['nl'], 'VA-ECMO': ['de', 'fi', 'nl'], 'VV-ECMO': ['de', 'fi', 'nl'], 'JPA': ['nl'], 'epidemic': ['da'], 'lockdown': ['it'], 'cleantech': ['da', 'fi'], 'PEPP': ['cs', 'de', 'es', 'fr', 'it', 'nl', 'pt'], 'PHEIC': ['it'], 'audioconference': ['nl'], 'audioconference call': ['nl'], 'IL': ['da', 'de', 'es', 'fr', 'pt'], 'interleukin': ['da'], 'interleukine': ['da', 'fr', 'nl'], 'AMC': ['nl'], '‘green lane’ border crossing': ['nl'], 'green lane': ['nl'], 'ACC': ['fr'], 'visor': ['es'], 'first responder': ['da'], 'receptor': ['cs', 'da', 'es', 'nl', 'pt'], 'ESI': ['da', 'de', 'it', 'nl'], 'IES': ['de'], 'NPI': ['nl'], 'NPIs': ['nl'], 'ECMO': ['cs', 'da', 'de', 'fi', 'fr', 'it', 'nl'], 'ECLS': ['cs', 'it'], 'VAV ECMO': ['cs'], 'COVID19 CMSS': ['cs', 'cs', 'fr', 'it', 'nl'], 'CMSS': ['cs'], 'SURE instrument': ['cs', 'de', 'es', 'fi', 'fr', 'it', 'nl'], 'SURE': ['cs', 'de', 'es', 'fi', 'fr', 'it', 'nl'], 'SURE mechanism': ['cs', 'de', 'es', 'fi', 'fr', 'it', 'nl'], 'remdesivir': ['cs', 'es', 'fr', 'it', 'nl', 'pt'], 'CRII+': ['cs', 'da', 'de', 'fi', 'fr', 'it', 'nl'], 'Coronavirus Response Investment Initiative Plus': ['da'], 'FFP': ['cs'], 'FFP mask': ['cs'], 'FFP1 mask': ['cs'], 'FFP2 mask': ['cs'], 'FFP3 mask': ['cs'], 'particulate respirator': ['nl'], 'respirator': ['nl', 'da'], 'maintenance-free dust respirator': ['nl'], 'respirator mask': ['nl'], 'hydroxychloroquine': ['fr'], 'PMMA': ['cs', 'da', 'de', 'fi', 'it', 'nl', 'pt'], 'polymethyl methacrylate': ['da'], 'plexiglass': ['it', 'it', 'nl'], 'COSME EFG': ['cs', 'cs', 'de', 'it', 'nl'], 'EFG': ['cs', 'it', 'nl'], 'Team Europe': ['da', 'fi'], 'RADT': ['it'], 'intensive care': ['nl'], 'COSME LGF': ['cs', 'cs', 'de', 'fi', 'it', 'nl'], 'LGF': ['cs', 'fi', 'it', 'nl'], 'IDFF': ['de', 'nl'], 'EGF': ['de'], 'HEF': ['de'], 'screening': ['cs', 'da', 'it', 'nl'], 'health screening': ['cs', 'da', 'it', 'nl'], 'medical screening': ['cs', 'da', 'it', 'nl'], 'GHRP': ['cs', 'it'], 'capsomere': ['it'], 'virion': ['cs', 'fr', 'nl'], 'ivermectin': ['cs'], 'inflammation': ['da', 'fr', 'nl'], 'SICR': ['cs', 'es', 'it', 'nl'], 'compassionate use': ['nl'], 'Access to COVID-19 Tools Accelerator': ['nl'], 'ERCC': ['cs', 'da', 'de', 'de', 'fi', 'fr', 'it', 'nl'], 'ERC': ['de'], 'ACE2': ['fi'], 'EBA': ['cs', 'fi'], 'myocardium': ['da', 'nl', 'nl'], 'pandemic': ['da', 'da'], 'headroom': ['it', 'nl'], 'hypoxia': ['da'], 'CPZ': ['fr'], 'chlorpromazine': ['fr'], 'favipiravir': ['cs', 'fr', 'it', 'nl', 'pt'], 'BAL': ['fi', 'it'], 'Next Generation EU': ['cs', 'da', 'de', 'es', 'fi', 'fr', 'nl', 'pt'], 'NextGenerationEU': ['cs', 'de', 'nl', 'pt'], 'NGEU': ['cs', 'da'], 'myocarditis': ['da', 'da', 'nl'], 'adaptive immunity': ['fr'], 'CEPI': ['cs', 'de', 'fi', 'it', 'nl', 'pt'], 'Coalition for Epidemic Preparedness Innovations': ['de', 'nl'], 'respiratory ventilator': ['da', 'nl'], 'ventilator': ['nl'], 'mechanical ventilator': ['nl'], 'lung ventilator': ['nl'], 'blood plasma': ['fi', 'fr', 'pt'], 'plasma': ['fi', 'fr', 'pt'], 'REACT-EU': ['cs', 'de', 'es', 'fr', 'it'], 'API': ['it', 'nl'], 'swab': ['nl']}\n",
      "**********\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# get the most diffused anglicims (ie words in English that also appaeared in other languages)\n",
    "import re\n",
    "conn = sqlite3.connect('db/iate-covid19.db')\n",
    "conn.row_factory = sqlite3.Row\n",
    "c = conn.cursor()\n",
    "\n",
    "# main query\n",
    "q = 'select c.id as id_concept, c.en_lexemes as en_lexemes, l.value as lexeme, l.lang as lang from concepts as c join lexemes as l on c.id = l.id_concept where l.lang !=\"en\";'\n",
    "c.execute(q)\n",
    "res = [dict(row) for row in c.fetchall()]\n",
    "#print(res)\n",
    "#print(\"*\"*10)\n",
    "\n",
    "# english keywords\n",
    "stoplist=['for','the','and','2019','joint','open','time','type','error','Equity','Growth','acquired','unit','audio','order','value','partial','app','Loan','extra','asset','assets','towards','single','Next','Generation','NextGenerationEU','sector','level','security','negative','frontier','operation','context','operations','network','communicable','agent','lay','period','body','means','Board','specific','against']\n",
    "kw_en ={}\n",
    "for elt in res:\n",
    "    lexemes = elt['en_lexemes'].split(', ')\n",
    "    for lex in lexemes:\n",
    "        kws = lex.split(' ')\n",
    "        for kw in kws:\n",
    "            if kw in kw_en and len(kw) > 2 and not(kw in stoplist):\n",
    "                kw_en[kw]= kw_en[kw]+1\n",
    "            else:\n",
    "                kw_en[kw]= 1\n",
    "#print(kw_en)\n",
    "with open('iate_data.covid19.english_keywords.csv', mode=\"w\") as fout:\n",
    "    for elt in sorted(kw_en, key=lambda x:kw_en[x],reverse=True):\n",
    "        fout.write(elt +','+str(kw_en[elt]) + \"\\n\")\n",
    "    \n",
    "\n",
    "# structure : anglicims['covid19']=['cs','fr']\n",
    "anglicisms={}\n",
    "anglicisms_part={}\n",
    "for elt in res:\n",
    "    en_lexs = elt['en_lexemes'].split(', ')\n",
    "    #print(elt['id_concept'], en_lexs)\n",
    "    r = re.compile(elt['lexeme'])\n",
    "    # lexeme is found (exactly or as a part) in one or more of the en lexemes\n",
    "    # to be done : conversely the lexeme is found as a part in one or maore the en_lexemes\n",
    "    matches = list(filter(r.search, en_lexs))\n",
    "    if len(matches)> 0:\n",
    "        #print(matches, elt['lexeme'], elt['lang'])\n",
    "        for match in matches:\n",
    "            if match in anglicisms:\n",
    "                existing = anglicisms[match]\n",
    "                existing.append(elt['lang'])\n",
    "                anglicisms[match]=existing\n",
    "            else:\n",
    "                anglicisms[match] = [elt['lang']]\n",
    "    else:\n",
    "        # if any of english keywords is present in lexeme\n",
    "        # conversely the lexeme is found as a part in one or maore the en_lexemes\n",
    "        sorted_en = sorted(en_lexs,reverse=True)\n",
    "        #sorted_en2 = sorted(en_lexs,reverse=False)\n",
    "        #print(sorted_en)\n",
    "        #print(sorted_en2)\n",
    "        #print(\"*\"*10)\n",
    "        r2 = re.compile(r'(' + '|'.join(sorted_en) + r')')\n",
    "        matches2 = list(filter(r.search, elt['lexeme']))\n",
    "        if len(matches)> 0:\n",
    "            #print(matches, elt['lexeme'], elt['lang'])\n",
    "            for match in matches:\n",
    "                if match in anglicisms_part:\n",
    "                    existing = anglicisms_part[match]\n",
    "                    existing.append(elt['lang'])\n",
    "                    anglicisms_part[match]=existing\n",
    "                else:\n",
    "                    anglicisms_part[match] = [elt['lang']]\n",
    "\n",
    "print(anglicisms) \n",
    "print(\"*\"*10)\n",
    "print(anglicisms_part)\n",
    "\n",
    "# write results to csv\n",
    "\n",
    "with open('iate_data.covid19.en_diffused.csv', mode=\"w\") as fout:\n",
    "    for elt in sorted(anglicisms, key=lambda x:len(anglicisms[x]),reverse=True):\n",
    "#        print(elt)\n",
    "#        print(anglicisms[elt])\n",
    "        fout.write(elt + \",\" + str(anglicisms[elt]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
